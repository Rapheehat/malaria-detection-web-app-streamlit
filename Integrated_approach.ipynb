{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4a1d33-aec4-452b-b3bc-0b0b603099a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.applications import InceptionV3, DenseNet121, MobileNetV2,Xception\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e6df8-b313-4c1b-b65c-e3d43e33fb40",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3248dfa-6c1a-44cb-a0c4-d40697ff0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset_path\n",
    "dataset_dir = 'cell_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b31b3e-03ab-4287-9aad-16188234f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parasitized Images: 13779\n",
      "Number of Uninfected Images: 13779\n",
      "\n",
      "Total Classes: 2, Total Images: 27558\n"
     ]
    }
   ],
   "source": [
    "# List all subdirectories (each representing a class)\n",
    "classes = os.listdir(dataset_dir)\n",
    "\n",
    "# Initialize a dictionary to store the count of images in each class\n",
    "class_count = {class_name: len(os.listdir(os.path.join(dataset_dir, class_name))) for class_name in classes}\n",
    "\n",
    "# Print the results\n",
    "for class_name, num_images in class_count.items():\n",
    "    print(f\"Number of {class_name} Images: {num_images}\")\n",
    "\n",
    "# Print the total number of classes and images\n",
    "total_classes = len(classes)\n",
    "total_images = sum(class_count.values())\n",
    "print(f\"\\nTotal Classes: {total_classes}, Total Images: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb162098-ce0f-44ce-928a-e41c9ed1e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           file_path       label\n",
      "0  cell_images\\Uninfected\\C100P61ThinF_IMG_201509...  Uninfected\n",
      "1  cell_images\\Uninfected\\C100P61ThinF_IMG_201509...  Uninfected\n",
      "2  cell_images\\Uninfected\\C100P61ThinF_IMG_201509...  Uninfected\n",
      "3  cell_images\\Uninfected\\C100P61ThinF_IMG_201509...  Uninfected\n",
      "4  cell_images\\Uninfected\\C100P61ThinF_IMG_201509...  Uninfected\n"
     ]
    }
   ],
   "source": [
    "# Define the paths to the folders containing the images\n",
    "uninfected_dir = os.path.join(dataset_dir, 'Uninfected')\n",
    "parasitized_dir = os.path.join(dataset_dir, 'Parasitized')\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images(folder, label):\n",
    "    return [(os.path.join(folder, filename), label) for filename in os.listdir(folder) if filename.endswith(\".png\")]\n",
    "\n",
    "# Load images and labels from both folders\n",
    "file_paths_labels = load_images(uninfected_dir, \"Uninfected\") + load_images(parasitized_dir, \"Parasitized\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = pd.DataFrame(file_paths_labels, columns=[\"file_path\", \"label\"])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Optionally, you can save the DataFrame to a CSV file\n",
    "data.to_csv(\"image_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37930ba-04ad-480a-bc65-0b3e4526de6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Uninfected     13779\n",
       "Parasitized    13779\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9247e16-ecd9-474d-9e0b-dc359e63b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"image_data.csv\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c950ae66-019c-4a1f-8c96-ef2283bb5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd2a32d-005c-4ea3-9a1c-4ccbe84a2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for creating data generator\n",
    "def create_data_generator(preprocessing_function, dataframe, x_col, y_col, batch_size=64, input_shape=(224, 224)):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "    generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        target_size=input_shape,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# Define function for feature extraction\n",
    "def extract_features(model, generator):\n",
    "    features = model.predict(generator, verbose=1)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "def train_and_evaluate_model(model, train_features, train_labels, test_features, test_labels):\n",
    "    model.fit(train_features, train_labels)\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    report = classification_report(test_labels, predictions)\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5653bc2-81a4-4c20-9381-d0d1cf8bca22",
   "metadata": {},
   "source": [
    "# Classifiers & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09ec610-4b60-4b04-864e-414554737de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers with default parameters\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"k-NN\": KNeighborsClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Define hyperparameters grid for each classifier\n",
    "param_grids = {\n",
    "    \"SVM\": {'C': [0.1, 1, 10]},\n",
    "    \"Random Forest\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n",
    "    \"k-NN\": {'n_neighbors': [3, 5, 10]},\n",
    "    \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c0aac-3227-4b1e-8f85-deaeaffa9485",
   "metadata": {},
   "source": [
    "# Model Definition, Feature Extraction, Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe0c5d-00ff-4c3c-926c-340a3de8ce0c",
   "metadata": {},
   "source": [
    "## MobileNetV2 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e2164a6-7c18-4e91-966c-543281ca5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MobileNetV2 model\n",
    "mobilenetv2_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Feature extraction for MobileNetV2\n",
    "mobilenetv2_model.trainable = False\n",
    "gap_mobilenetv2 = GlobalAveragePooling2D()(mobilenetv2_model.output)\n",
    "feature_extractor_mobilenetv2 = Model(inputs=mobilenetv2_model.input, outputs=gap_mobilenetv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca88b1f-0547-4067-af85-96134a9b98cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 validated image filenames belonging to 2 classes.\n",
      "Found 5512 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_generator_mobilenetv2 = create_data_generator(preprocess_input, train_df, \"file_path\", \"label\", 64, (224, 224))\n",
    "test_generator_mobilenetv2 = create_data_generator(preprocess_input, test_df, \"file_path\", \"label\", 64, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c60f0bd1-b1b2-41b7-a7ea-11a422037651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 570s 2s/step\n",
      "87/87 [==============================] - 115s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "train_features_mobilenetv2, train_labels_mobilenetv2 = extract_features(feature_extractor_mobilenetv2, train_generator_mobilenetv2)\n",
    "test_features_mobilenetv2, test_labels_mobilenetv2 = extract_features(feature_extractor_mobilenetv2, test_generator_mobilenetv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8304a8e-55ee-4d55-a431-59c3d28732db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MobileNetV2\n",
      "Tuning hyperparameters for SVM...\n",
      "Best parameters: {'C': 10}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.95\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2756\n",
      "           1       0.94      0.96      0.95      2756\n",
      "\n",
      "    accuracy                           0.95      5512\n",
      "   macro avg       0.95      0.95      0.95      5512\n",
      "weighted avg       0.95      0.95      0.95      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.93\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      2756\n",
      "           1       0.92      0.93      0.93      2756\n",
      "\n",
      "    accuracy                           0.93      5512\n",
      "   macro avg       0.93      0.93      0.93      5512\n",
      "weighted avg       0.93      0.93      0.93      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.94\n",
      "Test accuracy: 0.94\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2756\n",
      "           1       0.93      0.96      0.94      2756\n",
      "\n",
      "    accuracy                           0.94      5512\n",
      "   macro avg       0.94      0.94      0.94      5512\n",
      "weighted avg       0.94      0.94      0.94      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for k-NN...\n",
      "Best parameters: {'n_neighbors': 10}\n",
      "Best cross-validation accuracy: 0.88\n",
      "Test accuracy: 0.89\n",
      "Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88      2756\n",
      "           1       0.84      0.96      0.89      2756\n",
      "\n",
      "    accuracy                           0.89      5512\n",
      "   macro avg       0.89      0.89      0.89      5512\n",
      "weighted avg       0.89      0.89      0.89      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for AdaBoost...\n",
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.93\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2756\n",
      "           1       0.92      0.95      0.93      2756\n",
      "\n",
      "    accuracy                           0.93      5512\n",
      "   macro avg       0.93      0.93      0.93      5512\n",
      "weighted avg       0.93      0.93      0.93      5512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model\n",
    "for model_name, (train_features, train_labels, test_features, test_labels) in {\n",
    "    \"MobileNetV2\": (train_features_mobilenetv2, train_labels_mobilenetv2, test_features_mobilenetv2, test_labels_mobilenetv2),\n",
    "    }.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    # Perform hyperparameter tuning for each classifier\n",
    "    for classifier_name, clf in classifiers.items():\n",
    "        print(f\"Tuning hyperparameters for {classifier_name}...\")\n",
    "        param_grid = param_grids[classifier_name]\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
    "\n",
    "        # Train classifier with best parameters\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_clf.fit(train_features, train_labels)\n",
    "\n",
    "        # Evaluate classifier\n",
    "        test_accuracy, report = train_and_evaluate_model(best_clf, train_features, train_labels, test_features, test_labels)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"Classification Report for {classifier_name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f3f72-c7b7-44d3-b4b6-f6cf3531df6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac3ebde6-863c-4a20-866c-4ec4102e69c6",
   "metadata": {},
   "source": [
    "## DenseNet121 as a Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b41d6c-1976-467b-92f7-3d5e0bb89714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DenseNet121 model\n",
    "densenet121_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Feature extraction for DenseNet121 model\n",
    "densenet121_model.trainable = False\n",
    "gap_densenet121 = GlobalAveragePooling2D()(densenet121_model.output)\n",
    "feature_extractor_densenet121 = Model(inputs=densenet121_model.input, outputs=gap_densenet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9b0a5e-68c5-4236-a3a3-5be6b3322488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 validated image filenames belonging to 2 classes.\n",
      "Found 5512 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_generator_densenet121 = create_data_generator(preprocess_input, train_df, \"file_path\", \"label\", 64, (224, 224))\n",
    "test_generator_densenet121 = create_data_generator(preprocess_input, test_df, \"file_path\", \"label\", 64, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcbafc27-d572-4a76-8896-42c83b195593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 2267s 7s/step\n",
      "87/87 [==============================] - 478s 5s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "train_features_densenet121, train_labels_densenet121 = extract_features(feature_extractor_densenet121, train_generator_densenet121)\n",
    "test_features_densenet121, test_labels_densenet121 = extract_features(feature_extractor_densenet121, test_generator_densenet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1659afc4-74bd-4f30-93ea-6ed097386c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DenseNet121\n",
      "Tuning hyperparameters for SVM...\n",
      "Best parameters: {'C': 10}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.95\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      2756\n",
      "           1       0.94      0.96      0.95      2756\n",
      "\n",
      "    accuracy                           0.95      5512\n",
      "   macro avg       0.95      0.95      0.95      5512\n",
      "weighted avg       0.95      0.95      0.95      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.93\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      2756\n",
      "           1       0.93      0.93      0.93      2756\n",
      "\n",
      "    accuracy                           0.93      5512\n",
      "   macro avg       0.93      0.93      0.93      5512\n",
      "weighted avg       0.93      0.93      0.93      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.95\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2756\n",
      "           1       0.95      0.96      0.95      2756\n",
      "\n",
      "    accuracy                           0.95      5512\n",
      "   macro avg       0.95      0.95      0.95      5512\n",
      "weighted avg       0.95      0.95      0.95      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for k-NN...\n",
      "Best parameters: {'n_neighbors': 10}\n",
      "Best cross-validation accuracy: 0.89\n",
      "Test accuracy: 0.89\n",
      "Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89      2756\n",
      "           1       0.86      0.93      0.89      2756\n",
      "\n",
      "    accuracy                           0.89      5512\n",
      "   macro avg       0.89      0.89      0.89      5512\n",
      "weighted avg       0.89      0.89      0.89      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for AdaBoost...\n",
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.94\n",
      "Test accuracy: 0.94\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      2756\n",
      "           1       0.93      0.95      0.94      2756\n",
      "\n",
      "    accuracy                           0.94      5512\n",
      "   macro avg       0.94      0.94      0.94      5512\n",
      "weighted avg       0.94      0.94      0.94      5512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model\n",
    "for model_name, (train_features, train_labels, test_features, test_labels) in {\n",
    "    \"DenseNet121\": (train_features_densenet121, train_labels_densenet121, test_features_densenet121, test_labels_densenet121)\n",
    "    }.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    # Perform hyperparameter tuning for each classifier\n",
    "    for classifier_name, clf in classifiers.items():\n",
    "        print(f\"Tuning hyperparameters for {classifier_name}...\")\n",
    "        param_grid = param_grids[classifier_name]\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
    "\n",
    "        # Train classifier with best parameters\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_clf.fit(train_features, train_labels)\n",
    "\n",
    "        # Evaluate classifier\n",
    "        test_accuracy, report = train_and_evaluate_model(best_clf, train_features, train_labels, test_features, test_labels)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"Classification Report for {classifier_name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06bdf74-7361-464b-983b-79c6fe3d0a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2029a61b-83fa-4eaf-b747-436b95a8a440",
   "metadata": {},
   "source": [
    "## InceptionV3 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b352155a-15a6-428d-bdcd-65ee4f404c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define InceptionV3 model\n",
    "inceptionv3_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Feature extraction for InceptionV3\n",
    "inceptionv3_model.trainable = False\n",
    "gap_inceptionv3 = GlobalAveragePooling2D()(inceptionv3_model.output)\n",
    "feature_extractor_inceptionv3 = Model(inputs=inceptionv3_model.input, outputs=gap_inceptionv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c1ce01-e1b7-49c5-98ee-b652d38c6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 validated image filenames belonging to 2 classes.\n",
      "Found 5512 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_generator_inceptionv3 = create_data_generator(preprocess_input, train_df, \"file_path\", \"label\", 64, (299, 299))\n",
    "test_generator_inceptionv3 = create_data_generator(preprocess_input, test_df, \"file_path\", \"label\", 64, (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538c81c0-831e-43a9-abde-d15643736c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 2314s 7s/step\n",
      "87/87 [==============================] - 574s 7s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "train_features_inceptionv3, train_labels_inceptionv3 = extract_features(feature_extractor_inceptionv3, train_generator_inceptionv3)\n",
    "test_features_inceptionv3, test_labels_inceptionv3 = extract_features(feature_extractor_inceptionv3, test_generator_inceptionv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7f6291e-df22-4dad-94c5-a79c20037110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: InceptionV3\n",
      "Tuning hyperparameters for SVM...\n",
      "Best parameters: {'C': 10}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.94\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2756\n",
      "           1       0.93      0.96      0.94      2756\n",
      "\n",
      "    accuracy                           0.94      5512\n",
      "   macro avg       0.94      0.94      0.94      5512\n",
      "weighted avg       0.94      0.94      0.94      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.92\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2756\n",
      "           1       0.91      0.93      0.92      2756\n",
      "\n",
      "    accuracy                           0.92      5512\n",
      "   macro avg       0.92      0.92      0.92      5512\n",
      "weighted avg       0.92      0.92      0.92      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Best parameters: {'max_depth': 7, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.94\n",
      "Test accuracy: 0.94\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      2756\n",
      "           1       0.92      0.95      0.94      2756\n",
      "\n",
      "    accuracy                           0.94      5512\n",
      "   macro avg       0.94      0.94      0.94      5512\n",
      "weighted avg       0.94      0.94      0.94      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for k-NN...\n",
      "Best parameters: {'n_neighbors': 10}\n",
      "Best cross-validation accuracy: 0.88\n",
      "Test accuracy: 0.88\n",
      "Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87      2756\n",
      "           1       0.83      0.96      0.89      2756\n",
      "\n",
      "    accuracy                           0.88      5512\n",
      "   macro avg       0.89      0.88      0.88      5512\n",
      "weighted avg       0.89      0.88      0.88      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for AdaBoost...\n",
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.93\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      2756\n",
      "           1       0.92      0.95      0.93      2756\n",
      "\n",
      "    accuracy                           0.93      5512\n",
      "   macro avg       0.93      0.93      0.93      5512\n",
      "weighted avg       0.93      0.93      0.93      5512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model\n",
    "for model_name, (train_features, train_labels, test_features, test_labels) in {\n",
    "    \"InceptionV3\": (train_features_inceptionv3, train_labels_inceptionv3, test_features_inceptionv3, test_labels_inceptionv3)\n",
    "    }.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    # Perform hyperparameter tuning for each classifier\n",
    "    for classifier_name, clf in classifiers.items():\n",
    "        print(f\"Tuning hyperparameters for {classifier_name}...\")\n",
    "        param_grid = param_grids[classifier_name]\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
    "\n",
    "        # Train classifier with best parameters\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_clf.fit(train_features, train_labels)\n",
    "\n",
    "        # Evaluate classifier\n",
    "        test_accuracy, report = train_and_evaluate_model(best_clf, train_features, train_labels, test_features, test_labels)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"Classification Report for {classifier_name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c918c-2a77-4445-8b9f-8bf7cb9948fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbe5592c-c983-4cb3-8f0f-69a22629032f",
   "metadata": {},
   "source": [
    "## Xception as a Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de4186a-7506-484a-8b3c-9c6a35d79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Xception model\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Feature extraction for Xception model\n",
    "xception_model.trainable = False\n",
    "gap_xception = GlobalAveragePooling2D()(xception_model.output)\n",
    "feature_extractor_xception = Model(inputs=xception_model.input, outputs=gap_xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a8192e3-5583-492a-a7fc-caca3975ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 validated image filenames belonging to 2 classes.\n",
      "Found 5512 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_generator_xception = create_data_generator(preprocess_input, train_df, \"file_path\", \"label\", 64, (299, 299))\n",
    "test_generator_xception = create_data_generator(preprocess_input, test_df, \"file_path\", \"label\", 64, (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c930e98-5770-4856-902e-df51ef53fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 4381s 13s/step\n",
      "87/87 [==============================] - 1181s 14s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "train_features_xception, train_labels_xception = extract_features(feature_extractor_xception, train_generator_xception)\n",
    "test_features_xception, test_labels_xception = extract_features(feature_extractor_xception, test_generator_xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb5d8b0-7a2b-4be4-a354-9fee5bd33724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Xception\n",
      "Tuning hyperparameters for SVM...\n",
      "Best parameters: {'C': 1}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.95\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      2756\n",
      "           1       0.94      0.97      0.95      2756\n",
      "\n",
      "    accuracy                           0.95      5512\n",
      "   macro avg       0.95      0.95      0.95      5512\n",
      "weighted avg       0.95      0.95      0.95      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.92\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2756\n",
      "           1       0.92      0.93      0.93      2756\n",
      "\n",
      "    accuracy                           0.92      5512\n",
      "   macro avg       0.92      0.92      0.92      5512\n",
      "weighted avg       0.92      0.92      0.92      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.95\n",
      "Test accuracy: 0.95\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2756\n",
      "           1       0.94      0.96      0.95      2756\n",
      "\n",
      "    accuracy                           0.95      5512\n",
      "   macro avg       0.95      0.95      0.95      5512\n",
      "weighted avg       0.95      0.95      0.95      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for k-NN...\n",
      "Best parameters: {'n_neighbors': 10}\n",
      "Best cross-validation accuracy: 0.91\n",
      "Test accuracy: 0.91\n",
      "Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      2756\n",
      "           1       0.87      0.96      0.91      2756\n",
      "\n",
      "    accuracy                           0.91      5512\n",
      "   macro avg       0.91      0.91      0.91      5512\n",
      "weighted avg       0.91      0.91      0.91      5512\n",
      "\n",
      "\n",
      "Tuning hyperparameters for AdaBoost...\n",
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.93\n",
      "Test accuracy: 0.93\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      2756\n",
      "           1       0.93      0.94      0.93      2756\n",
      "\n",
      "    accuracy                           0.93      5512\n",
      "   macro avg       0.93      0.93      0.93      5512\n",
      "weighted avg       0.93      0.93      0.93      5512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model\n",
    "for model_name, (train_features, train_labels, test_features, test_labels) in {\n",
    "    \"Xception\": (train_features_xception, train_labels_xception, test_features_xception, test_labels_xception)\n",
    "    }.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    # Perform hyperparameter tuning for each classifier\n",
    "    for classifier_name, clf in classifiers.items():\n",
    "        print(f\"Tuning hyperparameters for {classifier_name}...\")\n",
    "        param_grid = param_grids[classifier_name]\n",
    "        grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
    "\n",
    "        # Train classifier with best parameters\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_clf.fit(train_features, train_labels)\n",
    "\n",
    "        # Evaluate classifier\n",
    "        test_accuracy, report = train_and_evaluate_model(best_clf, train_features, train_labels, test_features, test_labels)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"Classification Report for {classifier_name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9235b0-6dd4-4916-b1e4-6b4352d45b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
